Tutorial 1: Introduction to Neural Network and Deep Learning

- Deep learning -> Neural Networks -> Perceptron 
- ANN, CNN, RNN
- Jeoffrey Hinton -> invented back-propogation
- give a neural network, features and inputs. Train it to learn new things
- input layer -> layer of any number of neurons (hidden layer, line from each input to one neuron) -> output layer

_________________________________________________________________________________________

Tutorial 2: How does Neural Network work?
- Forward Propogation
  - inputs, weights assigned to inputs -> passed to hidden neuron
  - hidden neuron -> activation function
  - bias is added
  - weight updating happens with backwards propogation
  
_________________________________________________________________________________________

Tutorial 3: Activation Functions:
- Sigmoid Activation Function = used in logistic regressions = always used to get the final output in classification problems
- Relu Activation Function = used in regression and hidden layers of classification

_________________________________________________________________________________________

Tutorial 4: How to train neural networks with back-propogation:
- loss function, minimize loss and update weights
- requires back propogation to update weights
- learning rate (subtracted from old weight to get new weight on updation) must be very small
- vanishing and exploding gradient

_________________________________________________________________________________________

Tutorial 5: Multilayer Neural Network and Gradient Descent
- 


